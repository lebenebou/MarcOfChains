{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Marc of Chains - Final Project Graph Theory 2022\n",
    "## Youssef Yammine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This project is set to predict what Dr Marc Ibrahim will send to the team next using Markov chains\n",
    "# Every message posted by him 2021-2022 can be found in this directory under the filename \"MessageData.txt\"\n",
    "# Make sure to place both this file and current notebook file in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# CURRENT_DIR = os.path.dirname(__file__)\n",
    "# os.chdir(CURRENT_DIR) # change directory to current directory\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Message Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ['ravi', 'de', 'vous', 'rencontrer', '.', 'je', 'suis', 'desole', 'd', 'avoir', 'tarde', 'a', 'vous', 'accueillir', '.'] ...\n",
      "Total words in the message data: 2609\n"
     ]
    }
   ],
   "source": [
    "# Let's start by importing the words from our text file\n",
    "with open(\"./MessageData.txt\", 'r') as f:\n",
    "\n",
    "    words = f.read().split() # this is the list containing every word\n",
    "\n",
    "print(\"...\", words[22:37], \"...\")\n",
    "print(\"Total words in the message data:\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating The Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regrouper': 0.25, 'faire': 0.25, 'ouvrir': 0.25, 'resoudre': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# This function returns the possible following words that would come after the given word\n",
    "# It is a dictionary with words as keys and probability weights as values\n",
    "def next_possible_words(current_word):\n",
    "\n",
    "    answer = {} # empty dict\n",
    "    for i in range(len(words)-1):\n",
    "\n",
    "        if words[i]==current_word: # if given word is found, append next word (i+1) to the dict\n",
    "\n",
    "            if words[i+1] not in answer.keys():\n",
    "                answer[words[i+1]] = 1\n",
    "            else:\n",
    "                answer[words[i+1]] += 1\n",
    "\n",
    "    # So far we have every next possible word, along with how many times it occured\n",
    "    # To get the probability weights, we have to divide each occurence number with the total number of occurences\n",
    "    number_of_possibilities = sum(answer.values())\n",
    "\n",
    "    for key in answer.keys():\n",
    "        answer[key] = answer[key]/number_of_possibilities\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Try it for yourself with words like \"donc, faut, oui, c, j, quand, salle, ...\"\n",
    "print(next_possible_words(\"faut\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un probleme des videos sont dans l examen en comodal demain .\n"
     ]
    }
   ],
   "source": [
    "# This function returns a sentence starting with the given word\n",
    "# It keeps adding words from the markov chain until the word \".\" is reached\n",
    "def generate_sentence(starting_word):\n",
    "\n",
    "    sentence = starting_word\n",
    "\n",
    "    while starting_word!='.': # keep adding words until \".\" is reached\n",
    "\n",
    "        possibilities = next_possible_words(starting_word) # get all possible next words\n",
    "\n",
    "        # add next word to the sentence, taking probability weights into consideration\n",
    "        starting_word = random.choices(list(possibilities.keys()), weights=list(possibilities.values()))[0]\n",
    "        sentence += \" \"+starting_word\n",
    "\n",
    "    return sentence\n",
    "\n",
    "print(generate_sentence(\"un\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youssef Yammine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "572af174ac6dfe884f3dfdff25f6769f6ea6d0cc8dd5c0abe8955b94aa349043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
